capture log close
cd "/Users/danielle/Desktop/Python/Code"
log using "Kyle_Bailey_Danielle_Bauer_HW2.txt", replace text
clear
set type double

*Question 1(i)
*Holding expendB and prtystrA constant, a 1% increase in expendA results in a 
*(β1/100)% increase in voteA

*Question 1(ii)
*H0: β2 = – β1 or H0: β1 + β2 = 0

*Question 1(iii)
insheet using "/Users/danielle/Desktop/Python/Data/vote1.csv"
tab votea, m
tab expenda, m
tab expendb, m
tab prtystra, m

gen log_expenda = log(expenda)
gen log_expendb = log(expendb)

regress votea log_expenda log_expendb prtystra
*voteA = 45.0789 + 6.0833*log(expendA) - 6.6154*log(expendB) + 0.1520*prtystrA
*R-Squared = 0.793
*Sample Size = 173

*Yes, both expendA and expendB are statistically significant at the 1% 
*significance level
*Holding expendB and prtystrA constant, a 1% increase in expendA results in a
*0.06% increase in voteA
*Holding expendA and prtystrA constant, a 1% increase in expendB results in a 
*0.06% decrease in voteA

*No we cannot test the null hypothesis because we don't have the std error of
*β1 + β2 

*Take θ = β1 + β2 and rearrange to get β1 = θ – β2
*Plug into voteA = β0 + (θ – β2)*log(expendA) + β2*log(expendB) + β3*prtystrA + u
*and get: 
*voteA = β0 + θ*log(expendA) + β2[log(expendB) – log(expendA)] + β3*prtystrA + u

gen log_expendb_log_expenda = (log_expendb - log_expenda)
regress votea log_expenda log_expendb_log_expenda prtystra

*Since the t-stat for θ is ≈ -1, we fail to reject the null, meaning that the effect 
*that log(expendA) has on voteA is offset by log(expendB)

*Question 3
clear
insheet using "/Users/danielle/Desktop/Python/Data/hprice1.csv"
tab price, m
tab sqrft, m
tab bdrms, m

*Question 3(i&ii)
gen log_price = log(price)
regress log_price sqrft bdrms
*Take θ = 150*β1 + β2 and rearrange to get β2 = θ - 150*β1
*Plug into log(price) = β0 + β1*sqrft + (θ - 150*β1)*bdrms + u
*and get:
*log(price) = β0 + θ*bdrms + β1(sqrft - 150*bdrms) + u

gen sqrft_150bdrms = (sqrft - (150*bdrms))
regress log_price bdrms sqrft_150bdrms
*θ = 0.0858 

*Question 3(iii)
*Std Error of θ = 0.027 
display 0.0858 + (1.96*0.027)
*0.13872
display 0.0858 - (1.96*0.027)
*0.03288
*The 95% CI = [0.033,0.139] 

*Question 6(i&ii)
*lwage = β0 + β1*educ + β2*exper + β3*tenure + u
*H0: β2 = β3
*Take θ = β2 - β3 and rearrange to get β2 = θ + β3
*Plug into lwage = β0 + β1*educ + (θ + β3)*exper + β3*tenure + u
*and get:
*lwage = β0 + β1*educ + θ*exper + β3(exper + tenure) + u

clear
insheet using "/Users/danielle/Desktop/Python/Data/wage2.csv"
tab lwage, m
tab educ, m
tab exper, m

gen exper_and_tenure = (exper + tenure)
regress lwage educ exper exper_and_tenure
*Since the CI does include zero, we fail to reject the null, meaning
*that exper and tenure do have a same effect on lwage.

* Question 8(i)
clear
insheet using "ksubs.csv", comma names
drop if fsize != 1
describe
* There are 2017 single person households in the data set

* Question 8(ii)

reg nettfa inc age 
* nettfa = -43.0398 + 0.7993*inc + 0.8427*age
* The slope on income reads for a one unit ($1000) increase in annual income, we can expect a 0.7993 unit ($799.3) increase in net total financial assets
* The slope on age means that for a one year increase in age, we can expect a 0.8427 unit ($842.7) increase in net total financial assets

* Question 8(iii)
* The intercept does not have a lot of meaning, no. All else held to 0, (including age which wouldn't make much sense here) 
* you could expect to have -$43,039.80 in net financial assets.

* Question 8(iv)
ttest age == 1
* p-value is one-tailed area under curve of t-dist with df: 2014 (n=2017, k=2, 2017-2-1=2014) below t_stat (-1.70947)
* 0.0438
* At the 1% significance level, we fail to reject the null hypothesis that b2 = 1

* Question 8(v)
reg nettfa inc
* nettfa = -10.5710 + 0.8207*inc
* The coefficient on inc does not change much (0.7993 vs 0.8207), this is likely because (in theory) income is far more likely to be correlated with net financial asssets than age. 
* Two individuals can be the same age and make wildly different incomes
corr nettfa inc
* The correlation coefficient between the two variables is .2875, meaning they are fairly correlated within the data.

* Question 9(i)

clear 
insheet using "discrim.csv", comma names
gen prpblck1 = real(prpblck)
gen lincome1 = real(lincome)
gen lpsoda1 = real(lpsoda)
gen lhseval1 = real(lhseval)
gen prppov1 = real(prppov)
drop if missing(lincome1, prpblck1, lpsoda1, prppov1, lhseval1)
mdesc


reg lpsoda1 prpblck1 lincome1 prppov1
* lpsoda = -1.4633 + 0.0728prpblck + 0.1370 + 0.3804prppov
* At the 5% significance level, we reject the null hypothesis (0.018 < 0.05).
* At the 1% significance level, we fail to reject the null hypothesis (0.018 > 0.01).

* Question 9(ii)

corr lincome1 prppov1
* The variables lincome and prppov are highly correlated with a Pearson correlation coefficient of -0.8402.
* t-stat lincome: 5.119, p-value: 0.000
* t-stat prppov: 2.864, p-value: 0.004
* both variables are highly statistically significant (both p-values significant at the 1% level).

* Question 9(iii)

reg lpsoda1 prpblck1 lincome1 prppov1 lhseval1
* lpsoda = -0.8415 + 0.0976prpblck - 0.0530lincome + 0.0521prppov + 0.1213lhseval
* For a one percent increase in housing value, we can expect a .1213 percent increase in predicted price. 
* p-value = 0.000

* Question 9(iv)

* The variables lincome & prppov are no longer statistically significant following the inclusion of lhseval (p-values 0.159 & 0.699, respectively)
test lincome1=prppov1=0
* p-value = 0.03
* The variables are jointly significant at the 5% significance level.
* The variables are all highly correlated so all of their inclusion is likely to  skew the significance

* Question 9(v)

* In determining which model is more reliable in determining if racial makeups of zip codes influence fast food prices model 9_2 from 
* question (iii) is superior. prpblck (and lhseval) is significant at the 1% level and the other two are jointly significant at the 5% level. 
* Additionally, the model has a higher r2 and thus more explanatory power.
